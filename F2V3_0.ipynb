{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarieThe5454/ReposName/blob/main/F2V3_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 1: Import necessary libraries and load dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import shap"
      ],
      "metadata": {
        "id": "d5MUXwDsJo3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatically load and save dataset.\n",
        "!wget \"https://cloudstore.uni-ulm.de/s/R28JzBCTPEAdyRH/download\" -O churn_data.csv\n",
        "\n",
        "# Load the dataset as pandas dataframe\n",
        "churn_data = pd.read_csv('churn_data.csv')\n",
        "\n",
        "# Show dataset\n",
        "churn_data"
      ],
      "metadata": {
        "id": "u4af1ivgK23r",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 2: Data overview and initial visualization\n",
        "print(\"Dataset Information:\")\n",
        "print(churn_data.info())\n",
        "print(\"\\nSample Rows:\")\n",
        "print(churn_data.head())\n",
        "\n",
        "# Visualize churn distribution\n",
        "plt.figure(figsize=(6, 4))\n",
        "churn_data['Churn'].value_counts(normalize=True).plot(kind='bar', color=['blue', 'orange'])\n",
        "plt.title(\"Churn Distribution\")\n",
        "plt.xlabel(\"Churn (0 = No, 1 = Yes)\")\n",
        "plt.ylabel(\"Proportion\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "H_5SjEQ3XNCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 3: Correlation analysis and encoding categorical variables\n",
        "# Convert categorical features into numerical using One-Hot-Encoding\n",
        "churn_data_enc = pd.get_dummies(churn_data, columns=['Gender', 'Married'], drop_first=True)\n",
        "\n",
        "# Visualize correlations between features\n",
        "correlation_matrix = churn_data_enc.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kbnurYBpXJ_E",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 4: Feature selection and target assignment\n",
        "X = churn_data_enc.drop('Churn', axis=1)\n",
        "y = churn_data_enc['Churn']"
      ],
      "metadata": {
        "id": "17NxBttIUGeg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 5: Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "_XU9VIDBbfYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100],  # Reduced range\n",
        "    'max_depth': [10, 20],  # Reduced range\n",
        "    'min_samples_split': [2, 5],  # Fewer values\n",
        "    'min_samples_leaf': [1, 2]  # Fewer values\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    rf_model, param_grid, n_iter=5, cv=5, scoring='f1', n_jobs=-1, random_state=42\n",
        ")\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    rf_model, param_grid, n_iter=10, cv=3, scoring='f1', n_jobs=-1, random_state=42\n",
        ")\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Retrieve the best model\n",
        "best_model = random_search.best_estimator_\n"
      ],
      "metadata": {
        "id": "i_Bf3BR2bfPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Block 6: Hyperparameter tuning using RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier # Import the RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42) # Initialize the RandomForestClassifier model\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],  # Reduced range\n",
        "    'max_depth': [10, 20],  # Reduced range\n",
        "    'min_samples_split': [2, 5],  # Fewer values\n",
        "    'min_samples_leaf': [1, 2]  # Fewer values\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    rf_model, param_grid, n_iter=5, cv=5, scoring='f1', n_jobs=-1, random_state=42\n",
        ")\n",
        "\n",
        "# You can remove the redundant RandomizedSearchCV instantiation below\n",
        "# random_search = RandomizedSearchCV(\n",
        "#     rf_model, param_grid, n_iter=10, cv=3, scoring='f1', n_jobs=-1, random_state=42\n",
        "# )\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Retrieve the best model\n",
        "best_model = random_search.best_estimator_"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "azreR8R-Wn71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 7: Evaluate the model\n",
        "# Make predictions on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Print classification report and confusion matrix\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "my3u4VDQbfHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 8: Visualize feature importance\n",
        "feature_importances = pd.DataFrame(best_model.feature_importances_, index=X.columns, columns=['Importance'])\n",
        "feature_importances.sort_values(by='Importance', ascending=False).plot(kind='bar', figsize=(10, 6))\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I_w855Sqbe-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 9: SHAP analysis for model interpretability\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Visualize SHAP summary plot\n",
        "shap.summary_plot(shap_values[1], X_test, plot_type=\"bar\")"
      ],
      "metadata": {
        "id": "H1KPi-F6be10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 10: Recommendations based on insights\n",
        "print(\"Recommendations:\")\n",
        "print(\"- Focus retention strategies on customers showing high risk of churn based on key features.\")\n",
        "print(\"- Enhance customer engagement for at-risk groups identified in feature analysis.\")\n",
        "print(\"- Provide targeted offers or support to improve customer satisfaction and reduce churn.\")\n"
      ],
      "metadata": {
        "id": "jJtw4LWEb7UK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}